import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt

data = pd.read_excel('dataset.xlsx')
scaler = MinMaxScaler()
dataset = pd.DataFrame(scaler.fit_transform(data), columns=data.columns) 

# Isolation Forest model
iForest = IsolationForest(n_estimators=100, max_samples='auto', contamination='auto', random_state=40)
iForest.fit(dataset)

# Anomaly scores for each observation
scores = iForest.decision_function(dataset)

# Histogram of anomaly scores
plt.hist(scores, bins=70)
plt.xlabel('Decision Scoring')
plt.ylabel('Frequency')
plt.title('Histogram of Decision Scores')
plt.show()

# Defining the anomaly threshold, and finding anomalous observations
umbral=-0.06
anomaly=dataset[scores < umbral]

# Results
print("Number of anomalies detected:", len(anomaly))
print("Anomalies:",anomaly)
anomaly_index=anomaly.index
print("Anomaly indexes:", anomaly_index)
anomaly.to_excel('iForest_anomalies.xlsx')

# Confusion matrix
from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score
import seaborn as sns
dat = pd.read_excel('tdaytdf.xlsx')
etiq_verdadera=dat['anom']
etiq_predicha=dat['iForest']
cm = confusion_matrix(etiq_verdadera, etiq_predicha,labels=[0, 1])
print(cm)

# True Positives
VP = cm[0, 0]
# True Negatives
VN = cm[1, 1]
# False Positives (FP)
FP = cm[1, 0]
# False Negatives (FN)
FN = cm[0, 1]

TDA= VP/(VP+FN)  # Anomaly Detection Rate (ADR)
TFA=FP/(VN+FP)   # False Alarm Rate (FAR)
print("Anomaly Detection Rate (ADR):", TDA)
print("False Alarm Rate (FAR):", TFA)
